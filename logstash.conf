input {
  beats {
    port => 5044
  }
}

filter
{

  #use customerized patterns in /etc/logstash/patterns
  grok {
    patterns_dir => [ "/etc/logstash/patterns" ]
    patterns_files_glob => [ "*.conf" ]
    match => { "message" => "%{GREEDYDATA:prefix}%{CCBDATETIME:ccbtime}%{GREEDYDATA:postfix}" }
    remove_field => [ "message", "prefix", "postfix" ]
  }

  #drop grok parse failure event
  if "_grokparsefailure" in [tags] {
    drop { }
  }

  #parse the date time like: 2020-02-2018:15:30 699
  date {
    #timezone => "Asia/Shanghai"
    match => [ "ccbtime" , "yyyy-MM-ddHH:mm:ss SSS" ]
    target => "ccbtime2" // set parsed result to ccbtimes
  }

  ruby {
    init => "require 'time'"
    #set duration(@timestamp - ccbtimes) to log_duration field
    code => "duration = (event.get('@timestamp') - event.get('ccbtime2')) rescue nil; event.set('log_duration',
 duration); "
  }                                                                                          
                                                                                             
}

#output to elasticsearch
output {
  elasticsearch {
    hosts => ["0.0.0.0:9200"]
    index => "ccb2-log-%{+YYYY.MM.dd}"
    #user => "username"
    #password => "mypassword"
  }
  #stdout {codec => json_lines }
}


#output to local file
#output {
# file {
#    path => "/tmp/log/out.log"
#  }
#  stdout { codec => json_lines }
#}
